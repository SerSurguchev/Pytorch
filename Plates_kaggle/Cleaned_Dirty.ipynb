{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport shutil\nfrom tqdm import tqdm\nimport cv2\nfrom skimage.io import imread_collection\nfrom skimage import exposure\nimport random\nimport glob\nimport torch\nfrom PIL import Image\n\nfrom matplotlib import pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-10T18:46:17.983589Z","iopub.execute_input":"2022-05-10T18:46:17.983910Z","iopub.status.idle":"2022-05-10T18:46:20.085896Z","shell.execute_reply.started":"2022-05-10T18:46:17.983829Z","shell.execute_reply":"2022-05-10T18:46:20.085138Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import zipfile\nwith zipfile.ZipFile('../input/platesv2/plates.zip', 'r') as zip_obj:\n   # Extract all the contents of zip file in current directory\n   zip_obj.extractall('/kaggle/working/')","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:46:20.087613Z","iopub.execute_input":"2022-05-10T18:46:20.087825Z","iopub.status.idle":"2022-05-10T18:46:20.817259Z","shell.execute_reply.started":"2022-05-10T18:46:20.087799Z","shell.execute_reply":"2022-05-10T18:46:20.816510Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"print('After zip extraction:')\nprint(os.listdir(\"/kaggle/working/\"))\n\n\ndata_root = '/kaggle/working/plates/'\nprint(os.listdir(data_root))","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:46:20.820091Z","iopub.execute_input":"2022-05-10T18:46:20.820333Z","iopub.status.idle":"2022-05-10T18:46:20.826893Z","shell.execute_reply.started":"2022-05-10T18:46:20.820296Z","shell.execute_reply":"2022-05-10T18:46:20.825946Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_dir = 'train'\nval_dir = 'val'\n\ndata_root = '/kaggle/working/plates/'\n\nclass_names = ['cleaned', 'dirty']\n\nfor dir_name in [train_dir, val_dir]:\n    for class_name in class_names:\n        os.makedirs(os.path.join(dir_name, class_name), exist_ok=True)\n        \n        \nfor class_name in class_names:\n    source_dir = os.path.join(data_root, 'train', class_name)\n    for i, file_name in enumerate(tqdm(os.listdir(source_dir))):\n        if i % 6 != 0:\n            dest_dir = os.path.join(train_dir, class_name) \n        else:\n            dest_dir = os.path.join(val_dir, class_name)\n        shutil.copy(os.path.join(source_dir, file_name), os.path.join(dest_dir, file_name))","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:46:20.829784Z","iopub.execute_input":"2022-05-10T18:46:20.830398Z","iopub.status.idle":"2022-05-10T18:46:20.859206Z","shell.execute_reply.started":"2022-05-10T18:46:20.830331Z","shell.execute_reply":"2022-05-10T18:46:20.858530Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"images_train_0 = imread_collection('/kaggle/working/train/cleaned/*.jpg')\nimages_train_1 = imread_collection('/kaggle/working/val/dirty/*.jpg')\nlen(images_train_0), len(images_train_1)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:46:20.860411Z","iopub.execute_input":"2022-05-10T18:46:20.860641Z","iopub.status.idle":"2022-05-10T18:46:20.872168Z","shell.execute_reply.started":"2022-05-10T18:46:20.860610Z","shell.execute_reply":"2022-05-10T18:46:20.871490Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# im_example = Image.open('/kaggle/working/train/cleaned/0009.jpg')\n\n# for ex in glob.glob('/kaggle/working/train/cleaned/' + '*.jpg'):\n#     im_example = cv2.imread(ex)\n#     zoom_im = zoom(im_example, 0.7)\n#     plt.imshow(zoom_im, interpolation = 'nearest')\n#     plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:46:20.873599Z","iopub.execute_input":"2022-05-10T18:46:20.874003Z","iopub.status.idle":"2022-05-10T18:46:20.877688Z","shell.execute_reply.started":"2022-05-10T18:46:20.873965Z","shell.execute_reply":"2022-05-10T18:46:20.876812Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def rotate_image(im, angle):\n    \n    image_center = tuple(np.array(im.shape[1::-1]) / 2)\n    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n    result = cv2.warpAffine(im, rot_mat, im.shape[1::-1], flags=cv2.INTER_LINEAR)\n    return result\n \n    \ndef fill(img, h, w):\n    img = cv2.resize(img, (h, w), cv2.INTER_CUBIC)\n    return img\n\n\ndef zoom(im, value):\n    \n    \n    value = random.uniform(value, 1)\n    h, w, _ = im.shape\n    h_taken = int(value * h)\n    w_taken = int(value * w)\n    \n    h_start = random.randint(0, h - h_taken)\n    w_start = random.randint(0 , w - w_taken)\n    \n    img = im[h_start:h_start+h_taken, w_start:w_start+w_taken, :]\n    img = fill(img, h, w)\n    \n    return img \n\n\ndef data_augmentation(files_path, dataset_dir, class_dir):\n    \n    i = len(files_path)\n    \n    while (i > 0):\n        \n        path = files_path[i - 1]\n        image = cv2.imread(path)\n        \n        for angle in range(90, 360, 45):\n            rot = rotate_image(image, angle)\n            cv2.imwrite(f'/kaggle/working/{dataset_dir}/{class_dir}/000{i}rotate_{angle}.jpg', rot)\n            \n        for zoom_ratio in np.linspace(0.7, 0.9, 5, endpoint=True):\n            zoom_im = zoom(image, zoom_ratio)\n            cv2.imwrite(f'/kaggle/working/{dataset_dir}/{class_dir}/000{i}zoomed_{zoom_ratio}.jpg', zoom_im)\n        \n        \n        rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        flip = cv2.flip(image, 1)\n        \n        cv2.imwrite(f'/kaggle/working/{dataset_dir}/{class_dir}/000{i}rgb.jpg', rgb)\n        cv2.imwrite(f'/kaggle/working/{dataset_dir}/{class_dir}/000{i}flip.jpg', flip)\n        \n        i -= 1\n        \n        \ndef background_removal(files_path):\n    \n    for file_path in files_path:\n        #Load the Image\n        imgo = cv2.imread(file_path)\n        height, width = imgo.shape[:2]\n\n        #Create a mask holder\n        mask = np.zeros(imgo.shape[:2],np.uint8)\n\n        #Grab Cut the object\n        bgdModel = np.zeros((1,65),np.float64)\n        fgdModel = np.zeros((1,65),np.float64)\n\n        #Hard Coding the Rect The object must lie within this rect.\n        rect = (10,10,width-30,height-30)\n        cv2.grabCut(imgo,mask,rect,bgdModel,fgdModel,5,cv2.GC_INIT_WITH_RECT)\n        mask = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n        img1 = imgo*mask[:,:,np.newaxis]\n\n        #Get the background\n        background = imgo - img1\n\n        #Change all pixels in the background that are not black to white\n        background[np.where((background > [0,0,0]).all(axis = 2))] = [255,255,255]\n\n        #Add the background and the image\n        final = background + img1\n\n        cv2.imwrite(file_path, final)\n\ndef get_name_file(path_dir):\n    for root, dirs, files in os.walk(path_dir):\n        files = [path_dir + f for f in files if not f[0] == '.']\n    return files\n        \ndataset_dir = ['train', 'val']\nclass_names = ['cleaned', 'dirty']\n\n# /kaggle/working/train/cleaned/*.jpg\n\n\nfor dataset in dataset_dir:\n    for class_ in class_names:\n        files = get_name_file(f'/kaggle/working/'+ dataset + '/' + class_ + '/')\n        background_removal(files)\n        data_augmentation(files, dataset, class_)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:46:20.879165Z","iopub.execute_input":"2022-05-10T18:46:20.879629Z","iopub.status.idle":"2022-05-10T18:46:43.153339Z","shell.execute_reply.started":"2022-05-10T18:46:20.879591Z","shell.execute_reply":"2022-05-10T18:46:43.152600Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"%ls /kaggle/working/train/cleaned/*.jpg | wc -l\n%ls /kaggle/working/train/dirty/*.jpg | wc -l\n\n%ls /kaggle/working/val/cleaned/*.jpg | wc -l\n%ls /kaggle/working/val/dirty/*.jpg | wc -l","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:46:43.154568Z","iopub.execute_input":"2022-05-10T18:46:43.154841Z","iopub.status.idle":"2022-05-10T18:46:45.817145Z","shell.execute_reply.started":"2022-05-10T18:46:43.154808Z","shell.execute_reply":"2022-05-10T18:46:45.816368Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import torchvision\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader \nfrom torchvision import models\nimport torchvision.transforms as tt\nimport torch.nn as nn\n\nimport torch.optim as optim\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:46:45.818957Z","iopub.execute_input":"2022-05-10T18:46:45.819215Z","iopub.status.idle":"2022-05-10T18:46:45.972796Z","shell.execute_reply.started":"2022-05-10T18:46:45.819180Z","shell.execute_reply":"2022-05-10T18:46:45.972056Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_dir = 'train'\nval_dir = 'val'\n\ntrain_transforms = tt.Compose([\n    tt.CenterCrop(224),\n#     tt.RandomHorizontalFlip(),\n#     tt.RandomVerticalFlip(),\n    tt.ToTensor(),\n    tt.Lambda(lambda x: x[np.random.permutation(3), :, :]),\n    tt.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nval_transforms = tt.Compose([\n    tt.CenterCrop(224),\n    tt.ToTensor(),\n    tt.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n\ntrain_dataset = ImageFolder(train_dir, train_transforms)\nval_dataset = ImageFolder(val_dir, val_transforms)\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\nval_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=2)\n\nlen(train_dataloader), len(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:46:45.975828Z","iopub.execute_input":"2022-05-10T18:46:45.976062Z","iopub.status.idle":"2022-05-10T18:46:45.992445Z","shell.execute_reply.started":"2022-05-10T18:46:45.976027Z","shell.execute_reply":"2022-05-10T18:46:45.991735Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# def CalcMeanAndSTD(dataset):\n    \n#     loader = DataLoader(dataset, \n#                        batch_size = 10,\n#                        num_workers = 0,\n#                        shuffle = False)\n    \n#     mean = 0.0\n#     std = 0.0\n#     nb_samples = 0.0\n    \n#     for data, label in loader:\n#         batch_samples = data.size(0)\n#         # Rearrange batch to be the shape of [B, C, W * H]\n#         data = data.view(batch_samples, data.size(1), -1)\n        \n#         mean += data.mean(2).sum(0)\n#         std += data.std(2).sum(0)\n#         nb_samples += batch_samples\n    \n#     mean /= nb_samples\n#     std /= nb_samples\n    \n#     return mean, std\n\n# mean_val, std_val = CalcMeanAndSTD(train_dataset)\n\n\n# norm = tt.Normalize(mean = mean_val, std = std_val)\n\n# train_ds = norm(train_dataset)\n\n# val_ds = ImageFolder(val_dir, transform = tt.Compose([\n#     transforms.CenterCrop(224),\n#     transforms.ToTensor(),\n#     transforms.Normalize(mean = mean_val, std = std_val)\n# ]))","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:46:45.993687Z","iopub.execute_input":"2022-05-10T18:46:45.994162Z","iopub.status.idle":"2022-05-10T18:46:45.998869Z","shell.execute_reply.started":"2022-05-10T18:46:45.994127Z","shell.execute_reply":"2022-05-10T18:46:45.997994Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"mean = np.array([0.485, 0.456, 0.406])\nstd = np.array([0.229, 0.224, 0.225])\n\ndef show_input(input_tensor, title = ''):\n    image = input_tensor.permute(1,2,0).numpy()\n    \n    image = std * image + mean\n    plt.imshow(image.clip(0, 1))\n    plt.title(title)\n    plt.show()\n    plt.pause(0.001)\n\nX_batch, y_batch = next(iter(train_dataloader))\n\nfor x_item, y_item in zip(X_batch, y_batch):\n    show_input(x_item, title=class_names[y_item])","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:46:46.000236Z","iopub.execute_input":"2022-05-10T18:46:46.000715Z","iopub.status.idle":"2022-05-10T18:46:48.088077Z","shell.execute_reply.started":"2022-05-10T18:46:46.000679Z","shell.execute_reply":"2022-05-10T18:46:48.087021Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"seed = 21\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\n\nmodel = models.resnet50(pretrained=True)\n\n# Disable grad for all conv layers\nfor param in model.parameters():\n    param.requires_grad = False\n\nmodel.fc = nn.Sequential(nn.Dropout(0.4),nn.Linear(model.fc.in_features, 64),nn.ReLU(),\n                         nn.BatchNorm1d(num_features=64),nn.Dropout(0.3), nn.Linear(64,2))\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\nmodel = model.to(device)\n\nloss = nn.CrossEntropyLoss()\n\noptimizer = optim.Adam(model.parameters(), amsgrad = True, lr = 1e-3)\n\n# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n    factor=0.1, patience=10, threshold=0.0001, threshold_mode='abs')\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:46:48.089598Z","iopub.execute_input":"2022-05-10T18:46:48.090542Z","iopub.status.idle":"2022-05-10T18:47:02.828797Z","shell.execute_reply.started":"2022-05-10T18:46:48.090496Z","shell.execute_reply":"2022-05-10T18:47:02.827983Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def train_model(model, loss, optimizer, scheduler, num_epochs):\n        \n    loss_train = []\n    acc_train = []\n    \n    loss_val = []\n    acc_val = []\n    \n    for epoch in range(num_epochs):\n        print('Epoch {}/{}:'.format(epoch, num_epochs - 1), flush=True)\n\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                dataloader = train_dataloader\n\n                # Установить модель в режим обучения\n                model.train() \n            else:\n                dataloader = val_dataloader\n                # Установить модель в режим оценки\n                model.eval()\n\n            running_loss = 0.\n            running_acc = 0.\n\n            for inputs, labels in tqdm(dataloader):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                optimizer.zero_grad()\n\n                with torch.set_grad_enabled(phase == 'train'):\n                    preds = model(inputs)\n                    loss_value = loss(preds, labels)\n                    preds_class = preds.argmax(dim=1)\n\n                    if phase == 'train':\n                        loss_value.backward()\n                        optimizer.step()\n\n                running_loss += loss_value.item()\n                running_acc += (preds_class == labels.data).float().mean().cpu()\n\n            epoch_loss = running_loss / len(dataloader)\n            epoch_acc = running_acc / len(dataloader)\n            \n            if phase == 'val':\n                scheduler.step(epoch_loss)\n                \n#             scheduler.step()\n            \n            if phase == 'train':\n                loss_train.append(epoch_loss)\n                acc_train.append(epoch_acc)\n            else:\n                loss_val.append(epoch_loss)\n                acc_val.append(epoch_acc)\n                print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc), flush=True)\n\n    return loss_train, acc_train, loss_val, acc_val","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:47:02.830288Z","iopub.execute_input":"2022-05-10T18:47:02.830558Z","iopub.status.idle":"2022-05-10T18:47:02.843657Z","shell.execute_reply.started":"2022-05-10T18:47:02.830522Z","shell.execute_reply":"2022-05-10T18:47:02.841838Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"loss_train = {}\nacc_train = {}\nloss_val = {}\nacc_val = {}\n\nloss_train['loss_train'], acc_train['acc_train'], loss_val['loss_val'], acc_val['acc_val'] = \\\ntrain_model(model, loss, optimizer, scheduler, num_epochs=60)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:47:02.844910Z","iopub.execute_input":"2022-05-10T18:47:02.845327Z","iopub.status.idle":"2022-05-10T18:49:37.047049Z","shell.execute_reply.started":"2022-05-10T18:47:02.845271Z","shell.execute_reply":"2022-05-10T18:49:37.046158Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\nsns.set_style('darkgrid')\n\nsns.set(rc={'figure.figsize':(15, 10)})\n\n\ndef acc_loss_graph(losses_train, acc_train, losses_val, acc_val, save_file_name='plot.png', download=False):\n    \n    fig, (ax1, ax2) = plt.subplots(1, 2)\n    \n    for experiment_id in losses_train.keys():\n        ax1.plot(losses_train[experiment_id], label = experiment_id, c = 'red')\n        \n        \n    for experiment_id in acc_train.keys():\n        ax1.plot(acc_train[experiment_id], label = experiment_id, c = 'blue')\n    \n    ax1.legend()\n    \n    ax1.set_title('Accuracy')\n    \n    fig.tight_layout()\n    \n    \n    for experiment_id in losses_val.keys():\n        ax2.plot(losses_val[experiment_id], label = experiment_id, c = 'red')\n        \n        \n    for experiment_id in acc_val.keys():\n        ax2.plot(acc_val[experiment_id], label = experiment_id, c = 'blue')\n    \n    ax2.legend()\n    ax2.set_title('Losses')\n\n    \n    fig.tight_layout()\n    \n    if download:\n        fig.savefig(save_file_name)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:49:37.048667Z","iopub.execute_input":"2022-05-10T18:49:37.049483Z","iopub.status.idle":"2022-05-10T18:49:37.568909Z","shell.execute_reply.started":"2022-05-10T18:49:37.049440Z","shell.execute_reply":"2022-05-10T18:49:37.568092Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"acc_loss_graph(loss_train, acc_train, loss_val , acc_val)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:49:37.570102Z","iopub.execute_input":"2022-05-10T18:49:37.570379Z","iopub.status.idle":"2022-05-10T18:49:38.198942Z","shell.execute_reply.started":"2022-05-10T18:49:37.570329Z","shell.execute_reply":"2022-05-10T18:49:38.198231Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"test_dir = 'test'\nshutil.copytree(os.path.join(data_root, 'test'), os.path.join(test_dir, 'unknown'))","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:49:38.200240Z","iopub.execute_input":"2022-05-10T18:49:38.200719Z","iopub.status.idle":"2022-05-10T18:49:38.333992Z","shell.execute_reply.started":"2022-05-10T18:49:38.200679Z","shell.execute_reply":"2022-05-10T18:49:38.333115Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#Мы не знаем, какие ID, какие названия изображения у нас генерируется, когда мы просим у DataLoader -- \"дай нам следующий батч\".\n#Они по алфавиту идут, по дате создания, или просто случайным образом -- непонятно.\n#Поэтому нам нужно переписать немножко ImageFolder, чтобы он нам отдавал не просто tuple, с самим изображением и его меткой, а ещё, чтобы он отдавал имя, ну, либо -- путь к изображению.\n\nclass ImageFolderWithPaths(torchvision.datasets.ImageFolder):\n    def __getitem__(self, index):\n        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n        path = self.imgs[index][0]\n        tuple_with_path = (original_tuple + (path,))\n        return tuple_with_path\n    \ntest_dataset = ImageFolderWithPaths('/kaggle/working/test', val_transforms)\n\nbatch_size = 15\n\ntest_dataloader = torch.utils.data.DataLoader(\n    test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n\n    \nmodel.eval() #Переводим модель в состояние eval\ntest_predictions = []  #Создаем пустой список предсказания \ntest_img_paths = [] #Пути до изображения\nfor inputs, labels, paths in tqdm(test_dataloader): #Цикл по test_dataloader inputs - батч с изображением, lable - тут none, paths - пути до изображения  \n    inputs = inputs.to(device) \n    labels = labels.to(device)  \n    with torch.set_grad_enabled(False):\n        preds = model(inputs) # Считаем предикшены\n    test_predictions.append(\n        torch.nn.functional.softmax(preds, dim=1)[:,1].data.cpu().numpy()) #С помощью torch.nn.functional.softmax получаем вероятности, для первого класса [:,1], пеереводим тензор в .data, на .cpu(), в numpy \n    test_img_paths.extend(paths)\ntest_predictions = np.concatenate(test_predictions)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:49:38.335519Z","iopub.execute_input":"2022-05-10T18:49:38.336007Z","iopub.status.idle":"2022-05-10T18:49:42.189170Z","shell.execute_reply.started":"2022-05-10T18:49:38.335965Z","shell.execute_reply":"2022-05-10T18:49:42.188356Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"inputs, labels, paths = next(iter(test_dataloader))\n\nfor img, pred in zip(inputs, test_predictions):\n    show_input(img, title=pred)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:49:42.190588Z","iopub.execute_input":"2022-05-10T18:49:42.191227Z","iopub.status.idle":"2022-05-10T18:49:49.263988Z","shell.execute_reply.started":"2022-05-10T18:49:42.191187Z","shell.execute_reply":"2022-05-10T18:49:49.263378Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.DataFrame.from_dict({'id': test_img_paths, 'label': test_predictions})\nsubmission_df['label'] = submission_df['label'].map(lambda pred: 'dirty' if pred > 0.8 else 'cleaned')\nsubmission_df['id'] = submission_df['id'].str.replace('/kaggle/working/test/unknown/', '')\nsubmission_df['id'] = submission_df['id'].str.replace('.jpg', '')\nsubmission_df.set_index('id', inplace=True)\nsubmission_df","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:49:49.265424Z","iopub.execute_input":"2022-05-10T18:49:49.265857Z","iopub.status.idle":"2022-05-10T18:49:49.296886Z","shell.execute_reply.started":"2022-05-10T18:49:49.265821Z","shell.execute_reply":"2022-05-10T18:49:49.296185Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:49:49.298113Z","iopub.execute_input":"2022-05-10T18:49:49.298869Z","iopub.status.idle":"2022-05-10T18:49:49.306275Z","shell.execute_reply.started":"2022-05-10T18:49:49.298831Z","shell.execute_reply":"2022-05-10T18:49:49.305483Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# !rm -rf train val test","metadata":{"execution":{"iopub.status.busy":"2022-05-10T18:49:49.308202Z","iopub.execute_input":"2022-05-10T18:49:49.308475Z","iopub.status.idle":"2022-05-10T18:49:49.314791Z","shell.execute_reply.started":"2022-05-10T18:49:49.308448Z","shell.execute_reply":"2022-05-10T18:49:49.313772Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
