{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nimport torchvision\nfrom torchvision import models\nimport os\nimport time\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader \nimport torch.optim as optim\nimport torchvision.transforms as tt\nfrom torch.utils.data import random_split\nfrom torchvision.utils import make_grid\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-24T12:23:38.736287Z","iopub.execute_input":"2021-11-24T12:23:38.736746Z","iopub.status.idle":"2021-11-24T12:23:40.310634Z","shell.execute_reply.started":"2021-11-24T12:23:38.736657Z","shell.execute_reply":"2021-11-24T12:23:40.309912Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# preparing and check dataset\ndataset_dir = '../input/covid-19-xray-image-dataset-with-huge-samples/COVID/'\ntrain_dir = dataset_dir + '/train'\ntest_dir = dataset_dir + '/test'\n\nclasses = os.listdir(train_dir)\nprint(classes)\n# transform to tensor and std, mean calcutation\n# train and val data transform\n# training process","metadata":{"execution":{"iopub.status.busy":"2021-11-24T12:23:40.312168Z","iopub.execute_input":"2021-11-24T12:23:40.312403Z","iopub.status.idle":"2021-11-24T12:23:40.337879Z","shell.execute_reply.started":"2021-11-24T12:23:40.312371Z","shell.execute_reply":"2021-11-24T12:23:40.337172Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def check_numbers(imgs_path):\n    for cls in os.listdir(imgs_path):\n        print(f\"Class {cls} has len {len(os.listdir(imgs_path + '/' + cls))}\")\n        \nfolders = [train_dir, test_dir]\n\nfor fol in folders:\n    print(fol.split('/')[-1])\n    check_numbers(fol)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T12:23:40.342344Z","iopub.execute_input":"2021-11-24T12:23:40.342830Z","iopub.status.idle":"2021-11-24T12:23:41.075955Z","shell.execute_reply.started":"2021-11-24T12:23:40.342785Z","shell.execute_reply":"2021-11-24T12:23:41.075163Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# https://discuss.pytorch.org/t/computing-the-mean-and-std-of-dataset/34949\n\n# def CalcMeanAndSTD(dataset):\n#     loader = DataLoader(dataset, batch_size = 10, num_workers = 0, shuffle = False)\n\n#     mean = 0.\n#     std = 0.\n#     for images, _ in loader:\n#         # Rearrange batch to be the shape of [B, C, W * H]\n#         batch_samples = images.size(0)\n#         images = images.view(batch_samples, images.size(1), -1)       \n#         # Compute mean and std here\n#         mean += images.mean(2).sum(0)\n#         std += images.std(2).sum(0)\n\n#     mean /= len(loader.dataset)\n#     std /= len(loader.dataset)\n    \n#     return mean, std\n\n# mean_vals, std_vals = CalcMeanAndSTD(dataset)\n# print(mean_vals, std_vals)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T12:23:41.077396Z","iopub.execute_input":"2021-11-24T12:23:41.077930Z","iopub.status.idle":"2021-11-24T12:23:41.082432Z","shell.execute_reply.started":"2021-11-24T12:23:41.077891Z","shell.execute_reply":"2021-11-24T12:23:41.081545Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def data_transform(data_type = None):\n    if data_type == train_dir:\n        data_T = tt.Compose([\n            tt.Resize(size = (200,200)),\n            tt.RandomHorizontalFlip(),\n            tt.RandomGrayscale(),\n            tt.ToTensor()\n#             tt.Normalize(mean=mean_vals, std = std_vals)\n        ])\n    \n    elif data_type == test_dir:\n        data_T = tt.Compose([\n            tt.Resize(size = (200,200)),\n            tt.ToTensor()\n#             tt.Normalize(mean=mean_vals, std = std_vals)\n        ])\n        \n    return data_T\n\ntrain_data = ImageFolder(train_dir, transform = data_transform(train_dir))\ntest_data = ImageFolder(test_dir, transform = data_transform(test_dir))","metadata":{"execution":{"iopub.status.busy":"2021-11-24T12:23:41.083926Z","iopub.execute_input":"2021-11-24T12:23:41.084493Z","iopub.status.idle":"2021-11-24T12:23:42.223520Z","shell.execute_reply.started":"2021-11-24T12:23:41.084456Z","shell.execute_reply":"2021-11-24T12:23:42.222599Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(len(train_data))\nimg, label = train_data[0]\nprint(img.shape, label)\nimg","metadata":{"execution":{"iopub.status.busy":"2021-11-24T12:23:42.224946Z","iopub.execute_input":"2021-11-24T12:23:42.225429Z","iopub.status.idle":"2021-11-24T12:23:42.330532Z","shell.execute_reply.started":"2021-11-24T12:23:42.225392Z","shell.execute_reply":"2021-11-24T12:23:42.329810Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def show_image(img, label):\n    print(f'Dataset {train_data.classes[label]} - {str(label)}')\n    plt.imshow(img.permute(1,2,0))\n\n# img,label = dataset[0]\n# show_image(img,label)\nshow_image(*train_data[200])","metadata":{"execution":{"iopub.status.busy":"2021-11-24T12:23:42.331843Z","iopub.execute_input":"2021-11-24T12:23:42.332115Z","iopub.status.idle":"2021-11-24T12:23:42.592374Z","shell.execute_reply.started":"2021-11-24T12:23:42.332081Z","shell.execute_reply":"2021-11-24T12:23:42.591710Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"for i in range(5): \n    image,label = train_data[i]\n    print(image.shape,label)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T12:23:42.593568Z","iopub.execute_input":"2021-11-24T12:23:42.593967Z","iopub.status.idle":"2021-11-24T12:23:42.756357Z","shell.execute_reply.started":"2021-11-24T12:23:42.593931Z","shell.execute_reply":"2021-11-24T12:23:42.755559Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"val_size = 400\ntrain_size = len(train_data) - val_size\n\ntrain_dataset, val_dataset = random_split(train_data, [train_size, val_size])\nlen(train_dataset), len(val_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T12:23:42.759455Z","iopub.execute_input":"2021-11-24T12:23:42.759684Z","iopub.status.idle":"2021-11-24T12:23:42.770627Z","shell.execute_reply.started":"2021-11-24T12:23:42.759653Z","shell.execute_reply":"2021-11-24T12:23:42.769576Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_batch = DataLoader(train_dataset, batch_size = 32, shuffle = True, num_workers = 2, pin_memory = True)\nvalid_batch = DataLoader(val_dataset, batch_size= 64, shuffle = True, num_workers=2, pin_memory=True)\ntest_batch = DataLoader(test_data, batch_size = 32, shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T12:23:42.772776Z","iopub.execute_input":"2021-11-24T12:23:42.773322Z","iopub.status.idle":"2021-11-24T12:23:42.779000Z","shell.execute_reply.started":"2021-11-24T12:23:42.773285Z","shell.execute_reply":"2021-11-24T12:23:42.778156Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def show_batch(batch):\n    for images, labels in batch:\n        fig, ax = plt.subplots(figsize = (20,25))\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.imshow(make_grid(images, nrow = 16).permute(1, 2, 0))\n        break\n\nshow_batch(train_batch)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T12:23:42.781792Z","iopub.execute_input":"2021-11-24T12:23:42.782037Z","iopub.status.idle":"2021-11-24T12:23:49.414632Z","shell.execute_reply.started":"2021-11-24T12:23:42.782008Z","shell.execute_reply":"2021-11-24T12:23:49.413929Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T12:23:49.415822Z","iopub.execute_input":"2021-11-24T12:23:49.416102Z","iopub.status.idle":"2021-11-24T12:23:49.421577Z","shell.execute_reply.started":"2021-11-24T12:23:49.416067Z","shell.execute_reply":"2021-11-24T12:23:49.420934Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n    \ndef fit(epochs, model, train_loader, val_loader, criterion, optimizer, scheduler):\n    torch.cuda.empty_cache()\n    \n    train_losses = []\n    test_losses = []\n    train_scores = []\n    val_score = []\n    lrs = []\n    \n    fit_time = time.time()\n    for epoch in range(epochs):\n        since = time.time()\n        running_loss = 0\n        train_score = 0\n        \n        for image,label in train_loader:\n            \n            model.train()\n            image = image.to(device)\n            label = label.to(device)\n            output = model(image)\n            \n            # accuracy calculation\n            ps = torch.exp(output)\n            _, top_class = ps.topk(1, dim = 1)\n            correct = top_class == label.view(*top_class.shape)\n            train_score += torch.mean(correct.type(torch.FloatTensor))\n            \n            loss = criterion(output, label)\n            \n            loss.backward()\n            \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            scheduler.step()\n            lrs.append(get_lr(optimizer))\n            running_loss += loss.item()\n            \n        else:\n            model.eval()\n            test_loss = 0\n            scores = 0\n            #validation loop#\n            with torch.no_grad():\n                for image, label in val_loader:\n                    image = image.to(device); label = label.to(device);\n\n                    output = model(image)\n\n                    #accuracy calulcation\n                    ps = torch.exp(output)\n                    _, top_class = ps.topk(1, dim=1)\n                    correct = top_class == label.view(*top_class.shape)\n                    scores += torch.mean(correct.type(torch.FloatTensor))\n                    #loss\n                    loss = criterion(output, label)                                  \n                    test_loss += loss.item()\n            \n            #calculation mean for each batch\n            train_losses.append(running_loss/len(train_loader))\n            test_losses.append(test_loss/len(val_loader))\n            train_scores.append(train_score/len(train_loader))\n            val_score.append(scores/len(val_loader))\n\n            print(\"Epoch: {}/{}.. \".format(epoch+1, epochs),\n                  \"Train Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n                  \"Val Loss: {:.3f}.. \".format(test_loss/len(val_loader)),\n                  \"Train acc Score: {:.3f}.. \".format(train_score/len(train_loader)),\n                  \"Val acc : {:.3f}.. \".format(scores/len(val_loader)),\n                  \"Lr: {:.4f} \".format(get_lr(optimizer)),\n                  \"Time: {:.2f}s\" .format(time.time()-since)\n                 )\n        \n    history = {'train_loss' : train_losses, 'val_loss': test_losses, \n               'train_acc': train_scores, 'val_acc':val_score, 'lrs': lrs}\n    print('Total time: {:.2f} m' .format((time.time()- fit_time)/60))\n    return history","metadata":{"execution":{"iopub.status.busy":"2021-11-24T12:23:49.422836Z","iopub.execute_input":"2021-11-24T12:23:49.423237Z","iopub.status.idle":"2021-11-24T12:23:49.442475Z","shell.execute_reply.started":"2021-11-24T12:23:49.423203Z","shell.execute_reply":"2021-11-24T12:23:49.441631Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Mobilenet_v2 model","metadata":{}},{"cell_type":"code","source":"output_label = 2\n\nmodel_mobile = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n\nmodel_mobile.classifier = nn.Sequential(nn.Linear(in_features=1280, out_features=output_label))\n\nmodel_mobile.to(device)\n# model_mobile","metadata":{"execution":{"iopub.status.busy":"2021-11-24T12:23:49.443684Z","iopub.execute_input":"2021-11-24T12:23:49.444010Z","iopub.status.idle":"2021-11-24T12:23:53.538275Z","shell.execute_reply.started":"2021-11-24T12:23:49.443979Z","shell.execute_reply":"2021-11-24T12:23:53.537535Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"max_lr = 0.0001\nepoch = 20\nweight_decay = 1e-4\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model_mobile.parameters(), lr=max_lr, weight_decay=weight_decay)\nsched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epoch, \n                                            steps_per_epoch=len(train_batch))\n\nhistory_mobile = fit(epoch, model_mobile, train_batch, valid_batch, criterion, optimizer, sched)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T12:23:53.539637Z","iopub.execute_input":"2021-11-24T12:23:53.540051Z","iopub.status.idle":"2021-11-24T12:35:08.016502Z","shell.execute_reply.started":"2021-11-24T12:23:53.540014Z","shell.execute_reply":"2021-11-24T12:35:08.015631Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def plot_loss(history, n_epoch):\n    epoch = [x for x in range(1, n_epoch+1)]\n    plt.plot(epoch, history['train_loss'], label='Train_loss')\n    plt.plot(epoch, history['val_loss'], label='val_loss')\n    plt.title('Loss per epoch')\n    plt.ylabel('Loss')\n    plt.xlabel('epoch')\n    plt.legend() \n    plt.show()\n\ndef plot_score(history, n_epoch):\n    epoch = [x for x in range(1, n_epoch+1)]\n    plt.plot(epoch, history['train_acc'], label='Train_acc')\n    plt.plot(epoch, history['val_acc'], label='val_acc')\n    plt.title('Accuracy per epoch')\n    plt.ylabel('score')\n    plt.xlabel('epoch')\n    plt.legend()\n    plt.show()\n\ndef plot_lr(history):\n    plt.plot(history['lrs'], label='learning rate')\n    plt.title('One Cycle Learning Rate')\n    plt.ylabel('Learning Rate')\n    plt.xlabel('steps')\n    plt.legend() \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T12:35:08.018728Z","iopub.execute_input":"2021-11-24T12:35:08.019198Z","iopub.status.idle":"2021-11-24T12:35:08.029356Z","shell.execute_reply.started":"2021-11-24T12:35:08.019154Z","shell.execute_reply":"2021-11-24T12:35:08.028630Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"plot_score(history_mobile, epoch)\nplot_loss(history_mobile, epoch)\nplot_lr(history_mobile)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T12:35:08.030918Z","iopub.execute_input":"2021-11-24T12:35:08.031231Z","iopub.status.idle":"2021-11-24T12:35:08.661431Z","shell.execute_reply.started":"2021-11-24T12:35:08.031196Z","shell.execute_reply":"2021-11-24T12:35:08.660722Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Resnet18 Model","metadata":{}},{"cell_type":"code","source":"resnet_model = models.resnet18(pretrained = True)\nnum_fits = resnet_model.fc.in_features\n\nresnet_model.fc = nn.Linear(num_fits, 2)\nresnet_model = resnet_model.to(device)\n\n\nmax_lr = 0.0001\nepoch = 20\nweight_decay = 1e-4\n\ncriterion = nn.CrossEntropyLoss()\n# Observe that all parameters are being optimized\noptimizer = optim.Adam(resnet_model.parameters(), lr = max_lr, \n                       weight_decay=weight_decay)\n\nsched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=max_lr, \n                                            epochs = epoch, steps_per_epoch=len(train_batch))\n\nhistory_resnet18 = fit(epoch, resnet_model, train_batch, valid_batch, criterion, optimizer, sched)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T12:35:08.662687Z","iopub.execute_input":"2021-11-24T12:35:08.662992Z","iopub.status.idle":"2021-11-24T12:46:10.966199Z","shell.execute_reply.started":"2021-11-24T12:35:08.662954Z","shell.execute_reply":"2021-11-24T12:46:10.963899Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"plot_score(history_resnet18, epoch)\nplot_loss(history_resnet18, epoch)\nplot_lr(history_resnet18)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T12:46:10.967968Z","iopub.execute_input":"2021-11-24T12:46:10.968269Z","iopub.status.idle":"2021-11-24T12:46:11.588617Z","shell.execute_reply.started":"2021-11-24T12:46:10.968229Z","shell.execute_reply":"2021-11-24T12:46:11.587933Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\n\ntarget_labels = {\n    0: 'Covid Positive', \n    1: 'Covid Negative'\n}\n\ndef predict_dataset(dataset, model):\n    model.eval()\n    model.to(device)\n    torch.cuda.empty_cache()\n    predict = []\n    y_true = []\n    \n    for image, label in dataset:\n        image = image.unsqueeze(0)\n        image = image.to(device)\n \n        output = model(image)\n        ps = torch.exp(output)\n        _, top_class = ps.topk(1, dim = 1)\n        \n        predic = np.squeeze(top_class.cpu().numpy())\n        predict.append(predic)\n        y_true.append(label)\n        \n    return list(y_true), list(np.array(predict).reshape(1, -1).squeeze(0))\n\n\ndef report(y_true, y_predict, title:str):\n    print(classification_report(y_true, y_predict))\n    sns.heatmap(confusion_matrix(y_true, y_predict), annot = True)\n    plt.xticks(ticks = np.arange(0.5, len(target_labels)), labels = list(target_labels.values()), \n               rotation = 45)\n    \n    plt.yticks(ticks = np.arange(0.5, len(target_labels)), \n               labels = list(target_labels.values()), rotation = 0)\n    \n    plt.title(title)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-24T14:14:03.893756Z","iopub.execute_input":"2021-11-24T14:14:03.894479Z","iopub.status.idle":"2021-11-24T14:14:03.904367Z","shell.execute_reply.started":"2021-11-24T14:14:03.894436Z","shell.execute_reply":"2021-11-24T14:14:03.903605Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"y_true, y_predict = predict_dataset(test_data, model_mobile)\nreport(y_true, y_predict, title='Mobilenet_v2 Test Set')\n","metadata":{"execution":{"iopub.status.busy":"2021-11-24T14:07:23.543633Z","iopub.execute_input":"2021-11-24T14:07:23.544237Z","iopub.status.idle":"2021-11-24T14:07:32.400471Z","shell.execute_reply.started":"2021-11-24T14:07:23.544193Z","shell.execute_reply":"2021-11-24T14:07:32.399818Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"y_true, y_predict = predict_dataset(test_data, resnet_model)\nreport(y_true, y_predict, title = 'VGG16 Test Set')","metadata":{"execution":{"iopub.status.busy":"2021-11-24T14:26:50.824585Z","iopub.execute_input":"2021-11-24T14:26:50.825136Z","iopub.status.idle":"2021-11-24T14:26:58.637030Z","shell.execute_reply.started":"2021-11-24T14:26:50.825098Z","shell.execute_reply":"2021-11-24T14:26:58.636366Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
